{
  "description": "This research proposes a novel multi-agent reinforcement learning (MARL) algorithm named CAMMARL. The main idea is to model the actions of other agents as conformal prediction sets, which provide high-probability guarantees of containing the true actions. The algorithm aims to optimize an autonomous agentâ€™s decision-making capabilities in multi-agent environments. The performance of CAMMARL is demonstrated through various experiments in cooperative multi-agent tasks.",
  "title": {
    "value": "CAMMARL : Conformal Action Modeling in Multi Agent Reinforcement Learning",
    "justification": "The title is clearly stated at the top of the text.",
    "quote": "CAMMARL : Conformal Action Modeling in Multi Agent Reinforcement Learning"
  },
  "type": {
    "value": "Empirical Study",
    "justification": "The paper includes several experiments to demonstrate the performance of the proposed CAMMARL algorithm in different multi-agent environments.",
    "quote": "Through several experiments in two fully cooperative multi-agent tasks, we show that CAMMARL elevates the capabilities of an autonomous agent in MARL by modeling conformal prediction sets over the behavior of other agents."
  },
  "research_field": {
    "value": "Deep Learning",
    "justification": "The focus is on a novel algorithm for multi-agent reinforcement learning, a subfield of machine learning which is inherently a part of deep learning.",
    "quote": "In this article, we propose a novel multi-agent reinforcement learning (MARL) algorithm CAM MARL, which involves modeling the actions of other agents in different situations in the form of confident sets."
  },
  "sub_research_field": {
    "value": "Multi-Agent [[Reinforcement Learning]]",
    "justification": "The core contribution of the paper is an algorithm designed for multi-agent reinforcement learning scenarios.",
    "quote": "In this article, we propose a novel multi-agent reinforcement learning (MARL) algorithm CAM MARL , which involves modeling the actions of other agents in different situations in the form of confident sets, i.e., sets containing their true actions with a high probability."
  },
  "models": [
    {
      "name": {
        "value": "CAMMARL",
        "justification": "This is the main model proposed by the authors.",
        "quote": "In this article, we propose a novel multi-agent reinforcement learning (MARL) algorithm CAM MARL , which involves modeling the actions of other agents in different situations in the form of confident sets, i.e., sets containing their true actions with a high probability."
      },
      "role": "contributed",
      "type": {
        "value": "Multi-Agent Reinforcement Learning Model",
        "justification": "The model is specifically tailored for multi-agent reinforcement learning tasks.",
        "quote": "In this article, we propose a novel multi-agent reinforcement learning (MARL) algorithm CAM MARL , which involves modeling the actions of other agents in different situations in the form of confident sets, i.e., sets containing their true actions with a high probability."
      },
      "mode": "trained"
    },
    {
      "name": {
        "value": "PPO",
        "justification": "",
        "quote": "We use proximal policy optimization (PPO) (Schulman et al., 2017) to update the decision-making policy for both the RL agents"
      },
      "role": "used",
      "type": {
        "value": "Reinforcement Learning Algorithm",
        "justification": "",
        "quote": ""
      },
      "mode": "trained"
    },
    {
      "name": {
        "value": "MLP",
        "justification": "",
        "quote": "For the individual actor and critic networks, we used 2 fully-connected multi-layer perceptron (MLP) layers."
      },
      "role": "used",
      "type": {
        "value": "Neural Network",
        "justification": "",
        "quote": ""
      },
      "mode": "trained"
    }
  ],
  "datasets": [
    {
      "name": {
        "value": "Cooperative Navigation",
        "justification": "This dataset/environment is used in the experiments to test CAMMARL.",
        "quote": "We focus on four cooperative multi-agent environments: Cooperative Navigation."
      },
      "role": "used"
    },
    {
      "name": {
        "value": "Google Football",
        "justification": "This dataset/environment is used in the experiments to test CAMMARL.",
        "quote": "Finally, we also run CAMMARL in Google Football, where 3 agents try to score a goal against a defender and a keeper in a game of football."
      },
      "role": "used"
    },
    {
      "name": {
        "value": "Level-based Foraging",
        "justification": "This dataset/environment is used in the experiments to test CAMMARL.",
        "quote": "We focus on four cooperative multi-agent environments: Level-based Foraging."
      },
      "role": "used"
    },
    {
      "name": {
        "value": "Pressure Plate",
        "justification": "This dataset/environment is used in the experiments to test CAMMARL.",
        "quote": "Finally, we also run CAMMARL in Google Football, where 3 agents try to score a goal against a defender and a keeper in a game of football."
      },
      "role": "used"
    }
  ],
  "libraries": []
}