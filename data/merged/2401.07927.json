{
  "title": {
    "value": "Are self-explanations from Large Language Models faithful?",
    "justification": "The extracted title matches exactly as given in the user prompt.",
    "quote": "Are self-explanations from Large Language Models faithful?"
  },
  "description": "The paper investigates the faithfulness of self-explanations generated by instruction-tuned Large Language Models (LLMs). It proposes a method to measure faithfulness using self-consistency checks across different models and datasets. The findings indicate that faithfulness is highly model and task-dependent, suggesting that self-explanations from LLMs should not be trusted in general.",
  "type": {
    "value": "empirical",
    "justification": "The research involves experimental evaluation of language models and their explanations, making it empirical.",
    "quote": "In this paper, we evaluate the faithfulness of the following types of self-explanations."
  },
  "primary_research_field": {
    "value": "Natural Language Processing",
    "justification": "The paper primarily deals with the interpretability and faithfulness of explanations generated by NLP models.",
    "quote": "Instruction-tuned large language models (LLMs), such as Llama2 (Touvron et al., 2023), Falcon (Penedo et al., 2023), Mistral (Jiang et al., 2023), or GPT4 (OpenAI, 2023), are increasingly becoming mainstream among the general population, due to their capabilities and availability."
  },
  "sub_research_fields": [
    {
      "value": "Interpretability",
      "justification": "The focus of the paper is on evaluating the faithfulness of self-explanations generated by LLMs, which falls under interpretability in NLP.",
      "quote": "Our investigation reveals that self-explanationsâ€™ faithfulness is highly model and dataset-dependent."
    }
  ],
  "models": [
    {
      "name": {
        "value": "Falcon",
        "justification": "Falcon is one of the models used for evaluating faithfulness in self-explanations.",
        "quote": "For example, with sentiment classification, counterfactuals are more faithful for Llama2, importance measures for Mistral, and redaction for Falcon 40B."
      },
      "caracteristics": [
        {
          "value": "Large Language Model (LLM)",
          "justification": "Falcon is referred to as a large language model in the paper.",
          "quote": "Instruction-tuned large language models (LLMs), such as...Falcon (Penedo et al., 2023)"
        }
      ],
      "is_contributed": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_executed": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_compared": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Llama2",
        "justification": "The paper explicitly mentions using Llama2 for evaluating self-explanations.",
        "quote": "For example, with sentiment classification, counterfactuals are more faithful for Llama2."
      },
      "caracteristics": [
        {
          "value": "Large Language Model (LLM)",
          "justification": "Llama2 is referred to as a large language model in the paper.",
          "quote": "Instruction-tuned large language models (LLMs), such as Llama2 (Touvron et al., 2023)"
        }
      ],
      "is_contributed": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_executed": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_compared": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Llama2-70b",
        "justification": "",
        "quote": "List of models used in this paper. All models are publicly available."
      },
      "caracteristics": [
        {
          "value": "Large Language Model (LLM)",
          "justification": "",
          "quote": ""
        }
      ],
      "is_contributed": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_executed": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_compared": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Llama2-7b",
        "justification": "",
        "quote": "List of models used in this paper. All models are publicly available."
      },
      "caracteristics": [
        {
          "value": "Large Language Model (LLM)",
          "justification": "",
          "quote": ""
        }
      ],
      "is_contributed": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_executed": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_compared": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Mistral",
        "justification": "Mistral is another model evaluated for its faithfulness in providing self-explanations.",
        "quote": "For example, with sentiment classification, counterfactuals are more faithful for Llama2, importance measures for Mistral, and redaction for Falcon 40B."
      },
      "caracteristics": [
        {
          "value": "Large Language Model (LLM)",
          "justification": "Mistral is referred to as a large language model in the paper.",
          "quote": "Instruction-tuned large language models (LLMs), such as...Mistral (Jiang et al., 2023)"
        }
      ],
      "is_contributed": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_executed": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_compared": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    }
  ],
  "datasets": [
    {
      "name": {
        "value": "IMDB",
        "justification": "The paper uses the IMDB dataset for evaluating faithfulness in sentiment classification tasks.",
        "quote": "For example, regarding Llama2 (70B), counterfactuals only work with IMDB."
      },
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "MCTest",
        "justification": "The paper uses the MCTest dataset for evaluating faithfulness in multi-choice classification tasks.",
        "quote": "multi-choice classification (bAbI and MCTest Weston et al. 2016; Richardson et al. 2013)"
      },
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "RTE",
        "justification": "The paper uses the RTE dataset for evaluating faithfulness in two-paragraph classification tasks.",
        "quote": "two-paragraph classification (RTE Dagan et al. 2006)."
      },
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "bAbI",
        "justification": "The paper uses the bAbI dataset for multi-choice classification tasks.",
        "quote": "multi-choice classification (bAbI...Weston et al. 2016)"
      },
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    }
  ],
  "libraries": [
    {
      "name": {
        "value": "Hugging Face",
        "justification": "The paper uses the Hugging Face library for model implementation and experimentation.",
        "quote": "All generation inferences were made using Text Generation Inference (TGI) version 1.1.0 by Hug- gingFace (https://github.com/huggingface/ text-generation-inference)."
      },
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    }
  ]
}