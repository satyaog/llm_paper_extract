{
  "description": "The paper introduces Neural Progressive Meshes, a framework leveraging a neural network-based encoder-decoder architecture that derives a progressive compressed representation of 3D meshes for efficient transmission.",
  "title": {
    "value": "Neural Progressive Meshes",
    "justification": "The title is derived from the beginning of the research paper.",
    "quote": "Neural Progressive Meshes YUN-CHUN CHEN, University of Toronto, Canada VLADIMIR G. KIM, Adobe Research, USA NOAM AIGERMAN, Adobe Research, USA ALEC JACOBSON, Adobe Research, University of Toronto, Canada"
  },
  "type": {
    "value": "Empirical",
    "justification": "The study evaluates the proposed method using quantitative metrics and comparisons to several baseline methods, conducting multiple experiments.",
    "quote": "We evaluate our method on a diverse set of complex 3D shapes and demonstrate that it outperforms baselines in terms of compression ratio and reconstruction quality."
  },
  "research_field": {
    "value": "Computer Vision",
    "justification": "The paper addresses problems related to the efficient transmission and reconstruction of 3D meshes, which is a topic within the computer vision research field.",
    "quote": "arXiv:2308.05741v1 [cs.CV] 10 Aug 2023"
  },
  "sub_research_field": {
    "value": "3D Vision",
    "justification": "The work focuses on the processing, compression, and reconstruction of 3D meshes, fitting within the sub-research field of 3D Vision.",
    "quote": "We present a framework that learns a progressive compressed representation of meshes for transmission purposes."
  },
  "models": [
    {
      "name": {
        "value": "Neural Progressive Mesh",
        "justification": "This is the model introduced and developed in the paper.",
        "quote": "Fig. 1. Neural Progressive Meshes. We present a framework that learns a progressive compressed representation of meshes for transmission purposes."
      },
      "role": "contributed",
      "type": {
        "value": "Encoder-Decoder Architecture",
        "justification": "The model is described as an encoder-decoder architecture to derive a progressive compressed representation.",
        "quote": "We learn this space using a subdivision-based encoder-decoder architecture trained in advance on a large collection of surfaces."
      },
      "mode": "trained"
    },
    {
      "name": {
        "value": "Neural Subdivision",
        "justification": "Neural Subdivision, a pre-existing model, is adapted for the decoder in the framework.",
        "quote": "The client uses a subdivision-based decoder adapted from Neural Subdivision [Liu et al. 2020] to reconstruct a high-resolution mesh."
      },
      "role": "used",
      "type": {
        "value": "Geometric Deep Learning Model",
        "justification": "Neural Subdivision is categorized under geometric deep learning based on its approach to mesh reconstruction.",
        "quote": "We build upon the Neural Subdivision [Liu et al. 2020] framework."
      },
      "mode": "trained"
    },
    {
      "name": {
        "value": "SubdivNet",
        "justification": "SubdivNet is used within the neural network framework described.",
        "quote": "The server first uses TetWild [Hu et al. 2018] to preprocess it and then uses a subdivision-based encoder adapted from SubdivNet [Hu et al. 2022] to map geometric details of the original mesh."
      },
      "role": "used",
      "type": {
        "value": "Mesh Convolutional Network",
        "justification": "SubdivNet is a known approach in mesh-based deep learning.",
        "quote": "We follow recent advances in subdivision-based learning techniques for mesh analysis [Hanocka et al. 2019; Hu et al. 2022]"
      },
      "mode": "trained"
    }
  ],
  "datasets": [
    {
      "name": {
        "value": "Thingi10K",
        "justification": "This dataset is used to evaluate the proposed method.",
        "quote": "We evaluate our network on the Thingi10K [Zhou and Jacobson 2016] dataset, split into the training, validation, and test sets."
      },
      "role": "used"
    }
  ],
  "libraries": [
    {
      "name": {
        "value": "PyTorch",
        "justification": "PyTorch is used for training the neural networks involved in the study.",
        "quote": "We train our network using the ADAM [Kingma and Ba 2014] optimizer in PyTorch [Paszke et al. 2019]."
      },
      "role": "used"
    }
  ]
}