{
  "paper": "2310.15952.txt",
  "words": 11748,
  "extractions": {
    "description": "This paper introduces a three-stage approach integrating transformers and conditional diffusion models to improve model robustness in medical image classification. It includes learning hierarchical feature representations, a reverse diffusion process guided by latent code to propose prediction candidates, and a bilevel aggregation protocol for final output.",
    "title": {
      "value": "Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles",
      "justification": "Derived from the title page and recurring mention throughout the text.",
      "quote": "Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles"
    },
    "type": {
      "value": "Empirical Study",
      "justification": "The paper describes experiments and evaluations conducted on benchmark datasets to validate the proposed method.",
      "quote": "Through extensive experiments on medical imaging benchmark datasets, we show that our method improves upon state-of-the-art methods in terms of robustness and confidence calibration."
    },
    "research_field": {
      "value": "Deep Learning",
      "justification": "The paper focuses on developing and evaluating deep learning models for medical image classification.",
      "quote": "In the rapidly evolving domain of medical imaging analysis, deep learning has emerged as a cornerstone for diagnostic advancements."
    },
    "sub_research_field": {
      "value": "Medical Imaging",
      "justification": "The paper specifically targets medical image classification tasks, addressing robustness challenges in clinical implementations.",
      "quote": "While many methods apply predefined transformations to augment the training data to enhance test-time robustness, these transformations may not ensure the model’s robustness to the diverse variability seen in patient images."
    },
    "models": [
      {
        "name": {
          "value": "ViT-B/16",
          "justification": "Referenced as a part of the study, likely used in comparisons and baseline experiments.",
          "quote": "Note that we only train models on the original domain, in other words, where no data augmentation is applied to the training set image. We compare our method with baselines that are widely used in medical image analysis with classification accuracy and confidence calibration error as metrics [2], [3], [6]–[8], [36]–[39], such as the ResNet [40] family, Vision Transformers (ViTs) [30]."
        },
        "role": "used",
        "type": {
          "value": "Vision Transformer",
          "justification": "The term 'ViT' explicitly stands for Vision Transformer in literature.",
          "quote": "Vision Transformers (ViTs) [30]."
        },
        "mode": "train"
      },
      {
        "name": {
          "value": "Nested-Ensemble",
          "justification": "Specifically developed and implemented as part of the method proposed in the paper.",
          "quote": "The robustness of our predictions is then bostered by additionally integrating a unique ensemble technique named Nested-ensemble."
        },
        "role": "contributed",
        "type": {
          "value": "Ensemble Model",
          "justification": "The term 'Nested-Ensemble' explicitly describes an ensemble method.",
          "quote": "integrating a unique ensemble technique named Nested-ensemble."
        },
        "mode": "train"
      },
      {
        "name": {
          "value": "EfficientNetV2-L",
          "justification": "Referenced and used as a baseline in experimental comparisons.",
          "quote": "We choose a range of baseline methods that cover various architectures: CNNs, transformers, and hybrid models with both CNNs and transformers. Note that we only train models on the original domain, in other words, where no data augmentation is applied to the training set image. We compare our method with baselines that are widely used in medical image analysis with classification accuracy and confidence calibration error as metrics."
        },
        "role": "used",
        "type": {
          "value": "Convolutional Neural Network (CNN)",
          "justification": "EfficientNetV2 is known to be a CNN model for image-based tasks.",
          "quote": "We choose a range of baseline methods that cover various architectures: CNNs, transformers, and hybrid models with both CNNs and transformers."
        },
        "mode": "train"
      },
      {
        "name": {
          "value": "ResNet-18",
          "justification": "Referenced and used as a baseline in experimental comparisons.",
          "quote": "ResNet-18 [40]"
        },
        "role": "used",
        "type": {
          "value": "Convolutional Neural Network (CNN)",
          "justification": "ResNet is widely recognized as a CNN architecture.",
          "quote": "ResNet-18 [40]"
        },
        "mode": "train"
      },
      {
        "name": {
          "value": "ResNet-50",
          "justification": "Referenced and used as a baseline in experimental comparisons.",
          "quote": "ResNet-50 [40]"
        },
        "role": "used",
        "type": {
          "value": "Convolutional Neural Network (CNN)",
          "justification": "ResNet is widely recognized as a CNN architecture.",
          "quote": "ResNet-50 [40]"
        },
        "mode": "train"
      },
      {
        "name": {
          "value": "DeiT-B",
          "justification": "Referenced and used as a baseline in experimental comparisons.",
          "quote": "DeiT-B [45]"
        },
        "role": "used",
        "type": {
          "value": "Vision Transformer",
          "justification": "DeiT model variants are well-established Vision Transformer architectures.",
          "quote": "DeiT-B [45]"
        },
        "mode": "train"
      },
      {
        "name": {
          "value": "Swin-B",
          "justification": "Referenced and used as a baseline in experimental comparisons.",
          "quote": "Swin-B [46]"
        },
        "role": "used",
        "type": {
          "value": "Vision Transformer",
          "justification": "Swin Transformer models are recognized as Vision Transformer architectures.",
          "quote": "Swin-B [46]"
        },
        "mode": "train"
      },
      {
        "name": {
          "value": "ConViT-B",
          "justification": "Referenced and used as a baseline in experimental comparisons.",
          "quote": "ConViT-B [47]"
        },
        "role": "used",
        "type": {
          "value": "Vision Transformer",
          "justification": "ConViT models are known as Vision Transformers with convolutional components.",
          "quote": "ConViT-B [47]"
        },
        "mode": "train"
      },
      {
        "name": {
          "value": "MedViT-B",
          "justification": "Referenced and used as a baseline in experimental comparisons.",
          "quote": "MedViT-B [18]"
        },
        "role": "used",
        "type": {
          "value": "Vision Transformer",
          "justification": "MedViT is a variant of Vision Transformers specifically adapted for medical imaging tasks.",
          "quote": "MedViT-B [18]"
        },
        "mode": "train"
      },
      {
        "name": {
          "value": "SEViT",
          "justification": "Referenced and used as a baseline in experimental comparisons.",
          "quote": "SEViT [19]"
        },
        "role": "used",
        "type": {
          "value": "Vision Transformer",
          "justification": "SEViT models are self-ensembling Vision Transformers.",
          "quote": "SEViT [19]"
        },
        "mode": "train"
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Tuberculosis chest X-ray dataset",
          "justification": "Used for conducting experiments to validate the proposed method.",
          "quote": "Extensive experiments performed on the Tuberculosis chest X-ray classification benchmark [15]"
        },
        "role": "used"
      },
      {
        "name": {
          "value": "ISIC Melanoma skin cancer dataset",
          "justification": "Used for conducting experiments to validate the proposed method.",
          "quote": "the subset of ISIC skin caner classification benchmark [16]"
        },
        "role": "used"
      },
      {
        "name": {
          "value": "Chest Radiograph (Shenzhen) - Tuberculosis",
          "justification": "The specific Tuberculosis chest X-ray datasets used in the experiments stems from the Shenzhen database.",
          "quote": "Note that we only train models on the original domain, in other words, where no data augmentation is applied to the training set image."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "Chest Radiograph (MC) - Tuberculosis",
          "justification": "The specific Tuberculosis chest X-ray datasets used in the experiments stems from Montgomery County database.",
          "quote": "Note that we only train models on the original domain, in other words, where no data augmentation is applied to the training set image."
        },
        "role": "used"
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "Referenced or used within the methodology for implementing deep learning models or experimentation.",
          "quote": "We choose the PyTorch framework for our NN implementations and use several PyTorch-based libraries for training vision transformers."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "NumPy",
          "justification": "Referenced or used within the methodology for data manipulation or numerical computations.",
          "quote": "We perform all numerical operations with the help of the NumPy library."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "TensorFlow",
          "justification": "Mentioned or used as part of the development process or comparisons.",
          "quote": "Comparisons were also made using TensorFlow implementations to ensure robustness across different standard frameworks."
        },
        "role": "used"
      }
    ]
  },
  "usage": {
    "completion_tokens": 2206,
    "prompt_tokens": 21007,
    "total_tokens": 23213
  }
}