{
  "paper": "2309.06497.txt",
  "words": 19013,
  "extractions": {
    "description": "The paper describes a PyTorch implementation of the Distributed Shampoo algorithm for training neural networks at scale. This implementation is optimized for homogeneous GPU architectures and enables efficient multi-GPU distributed data-parallel training.",
    "title": {
      "value": "A Distributed Data-Parallel PyTorch Implementation of the Distributed Shampoo Optimizer for Training Neural Networks At-Scale",
      "justification": "The title is taken directly from the paper, providing an accurate and concise description of the study.",
      "quote": "A Distributed Data-Parallel PyTorch Implementation of the Distributed Shampoo Optimizer for Training Neural Networks At-Scale"
    },
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes empirical evaluations such as ablation studies and performance benchmarks on training ImageNet with ResNet50.",
      "quote": "We validate our implementation by performing an ablation study on training ImageNet ResNet50"
    },
    "research_field": {
      "value": "Deep Learning",
      "justification": "The research focuses on the implementation and optimization of a deep learning optimizer for training neural networks.",
      "quote": "Shampoo is an online and stochastic optimization algorithm belonging to the AdaGrad family of methods for training neural networks."
    },
    "sub_research_field": {
      "value": "Neural Network Optimization",
      "justification": "The main contribution of the paper is in the field of optimizing neural network training using the Distributed Shampoo optimizer.",
      "quote": "The contribution of this paper is the description and design of a PyTorch implementation of the Distributed Shampoo algorithm."
    },
    "models": [
      {
        "name": {
          "value": "ResNet50",
          "justification": "The ResNet50 model is used for evaluating the performance of the Distributed Shampoo implementation.",
          "quote": "We validate our implementation by performing an ablation study on training ImageNet ResNet50"
        },
        "role": "Used",
        "type": {
          "value": "Convolutional Neural Network",
          "justification": "ResNet50 is a widely-known architecture of convolutional neural networks designed for image recognition tasks.",
          "quote": "We validate our implementation by performing an ablation study on training ImageNet ResNet50"
        },
        "mode": "Training"
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "The ImageNet dataset is used for training the ResNet50 model to validate the Distributed Shampoo implementation.",
          "quote": "We validate our implementation by performing an ablation study on training ImageNet ResNet50"
        },
        "role": "Used"
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The Distributed Shampoo implementation is specifically designed for the PyTorch framework.",
          "quote": "A Distributed Data-Parallel PyTorch Implementation of the Distributed Shampoo Optimizer for Training Neural Networks At-Scale"
        },
        "role": "Used"
      }
    ]
  },
  "usage": {
    "completion_tokens": 512,
    "prompt_tokens": 39777,
    "total_tokens": 40289
  }
}