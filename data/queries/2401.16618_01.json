{
  "paper": "2401.16618.txt",
  "words": 5841,
  "extractions": {
    "description": "This paper explores and compares the use of centralized Deep Q-Network (DQN) controllers with traditional PID controllers for 6-DOF swimming robots in underwater object tracking tasks. It aims to illustrate the advantages of using RL-based controllers in such complex environments, showcasing improved performance and adaptability compared to traditional methods.",
    "title": {
      "value": "A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking",
      "justification": "This title encompasses the main focus of the paper, which compares RL-based controllers with PID controllers for specific applications related to 6-DOF swimming robots and underwater object tracking.",
      "quote": "A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking"
    },
    "type": {
      "value": "empirical study",
      "justification": "The study includes experiments conducted within a Unity-based simulator to validate the effectiveness of a centralized RL agent over PID controllers, indicating it is empirical in nature.",
      "quote": "Our experiments, conducted within a Unity-based simulator, validate the effectiveness of a centralized RL agent over separated PID controllers."
    },
    "research_field": {
      "value": "Deep Learning",
      "justification": "The paper uses Deep Q-Networks (DQN), a Deep Learning approach, to control 6-DOF swimming robots, making its primary research field Deep Learning.",
      "quote": "In this paper, we present an exploration and assessment of employing a centralized deep Q-network (DQN) controller as a substitute for the prevalent use of PID controllers in the context of 6DOF swimming robots."
    },
    "sub_research_field": {
      "value": "Reinforcement Learning",
      "justification": "The focus is on applying Deep Q-Networks, an approach within Reinforcement Learning, to control robots, making the sub-research field Reinforcement Learning.",
      "quote": "Our primary focus centers on illustrating this transition with the specific case of underwater object tracking. DQN offers advantages such as data efficiency and off-policy learning, while remaining simpler to implement than other reinforcement learning methods."
    },
    "models": [
      {
        "name": {
          "value": "Deep Q-Network (DQN)",
          "justification": "The paper explores the application of DQN for controlling 6-DOF swimming robots, highlighting its practical advantages.",
          "quote": "Our primary focus centers on illustrating this transition with the specific case of underwater object tracking. DQN offers advantages such as data efficiency and off-policy learning, while remaining simpler to implement than other reinforcement learning methods."
        },
        "role": "used",
        "type": {
          "value": "Reinforcement Learning Model",
          "justification": "DQN falls under the category of Reinforcement Learning models, emphasizing learning policies to maximize cumulative reward.",
          "quote": "DQN offers advantages such as data efficiency and off-policy learning, while remaining simpler to implement than other reinforcement learning methods."
        },
        "mode": "trained"
      },
      {
        "name": {
          "value": "YOLOv7",
          "justification": "The paper employs YOLOv7 for object detection as part of its vision module, which is integral to the research on underwater object tracking.",
          "quote": "We have adopted the methodology outlined in [5], using YOLOv7 for object detection, and then employing SORT for detection matching and implementing tracking-by-detection."
        },
        "role": "used",
        "type": {
          "value": "Object Detection Model",
          "justification": "YOLOv7 is known for its application in the object detection domain, making it an object detection model.",
          "quote": "Our study uses deep learning-based object detection models like YOLO [24], R-CNN [25], and SSD [26], which are widely used for real-world tasks and being continually improved [27], [28]."
        },
        "mode": "inference"
      },
      {
        "name": {
          "value": "SORT",
          "justification": "SORT is used for detection matching and implementing tracking-by-detection in the vision module of the study.",
          "quote": "We have adopted the methodology outlined in [5], using YOLOv7 for object detection, and then employing SORT for detection matching and implementing tracking-by-detection."
        },
        "role": "used",
        "type": {
          "value": "Tracking Model",
          "justification": "SORT is a tracking algorithm used in conjunction with object detection models to maintain continuous tracking of objects.",
          "quote": "To enhance temporal stability during tracking, we incorporate the methodology from previous work [5], [21], merging YOLO with SORT."
        },
        "mode": "inference"
      },
      {
        "name": {
          "value": "R-CNN",
          "justification": "R-CNN is listed among the deep learning-based object detection models used for underwater object detection in the related work section.",
          "quote": "Our study uses deep learning-based object detection models like YOLO [24], R-CNN [25], and SSD [26], which are widely used for real-world tasks and being continually improved [27], [28]."
        },
        "role": "referenced",
        "type": {
          "value": "Object Detection Model",
          "justification": "R-CNN is recognized in the field for its contributions to object detection, thereby falling under this category.",
          "quote": "Our study uses deep learning-based object detection models like YOLO [24], R-CNN [25], and SSD [26], which are widely used for real-world tasks and being continually improved [27], [28]."
        },
        "mode": "inference"
      },
      {
        "name": {
          "value": "SSD",
          "justification": "SSD is another deep learning-based object detection model mentioned in the related work section for its use in underwater detection tasks.",
          "quote": "Our study uses deep learning-based object detection models like YOLO [24], R-CNN [25], and SSD [26], which are widely used for real-world tasks and being continually improved [27], [28]."
        },
        "role": "referenced",
        "type": {
          "value": "Object Detection Model",
          "justification": "Single Shot MultiBox Detector (SSD) is widely recognized as an object detection model in the field of computer vision.",
          "quote": "Our study uses deep learning-based object detection models like YOLO [24], R-CNN [25], and SSD [26], which are widely used for real-world tasks and being continually improved [27], [28]."
        },
        "mode": "inference"
      }
    ],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "OpenAI Gym",
          "justification": "The paper references OpenAI Gym as a widely adopted reinforcement learning environment for its simulated experiments.",
          "quote": "This model is widely adopted in many benchmark environments of OpenAIGym/MuJoCo [50], [51]."
        },
        "role": "referenced"
      },
      {
        "name": {
          "value": "MuJoCo",
          "justification": "MuJoCo is mentioned as another benchmark environment utilized for reinforcement learning implementations in the study.",
          "quote": "This model is widely adopted in many benchmark environments of OpenAIGym/MuJoCo [50], [51]."
        },
        "role": "referenced"
      }
    ]
  },
  "usage": {
    "completion_tokens": 1333,
    "prompt_tokens": 9850,
    "total_tokens": 11183
  }
}