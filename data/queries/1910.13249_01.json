{
  "paper": "1910.13249.txt",
  "words": 8469,
  "extractions": {
    "title": {
      "value": "Navigation Agents for the Visually Impaired: A Sidewalk Simulator and Experiments",
      "justification": "This is the exact title of the paper as provided.",
      "quote": "Navigation Agents for the Visually Impaired: A Sidewalk Simulator and Experiments"
    },
    "description": "The paper introduces SEVN, a sidewalk simulation environment, and a neural network-based approach for creating navigation agents for the visually impaired. It addresses the inadequacies of existing reinforcement learning environments for sidewalk navigation and proposes a multi-modal observation method to improve navigation. The paper also provides a dataset and experimental results to spark further research in assistive navigation for the visually impaired.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes introducing a dataset, proposing a model, and conducting experiments to validate the approach. These are characteristics of empirical research.",
      "quote": "This work introduces SEVN, a sidewalk simulation environment and a neural network-based approach to creating a navigation agent. SEVN contains panoramic images with labels for house numbers, doors, and street name signs, and formulations for several navigation tasks. We study the performance of an RL algorithm (PPO) in this setting."
    },
    "primary_research_field": {
      "value": "Deep Learning",
      "justification": "The paper involves using neural networks and reinforcement learning, which are core areas of deep learning.",
      "quote": "This work introduces SEVN, a sidewalk simulation environment and a neural network-based approach to creating a navigation agent."
    },
    "sub_research_fields": [
      {
        "value": "Reinforcement Learning",
        "justification": "The primary method of agent training explained in the paper is Proximal Policy Optimization, which is a reinforcement learning algorithm.",
        "quote": "We study the performance of an RL algorithm (PPO) in this setting."
      }
    ],
    "models": [
      {
        "name": {
          "value": "Proximal Policy Optimization (PPO)",
          "justification": "The paper explicitly mentions using the PPO algorithm for training the navigation agents.",
          "quote": "We study the performance of an RL algorithm (PPO) in this setting."
        },
        "caracteristics": [
          {
            "value": "Reinforcement Learning Model",
            "justification": "PPO is a well-known reinforcement learning model used for training policies in various environments.",
            "quote": "We study the performance of an RL algorithm (PPO) in this setting."
          }
        ],
        "is_contributed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Multi-Modal Fusion Model",
          "justification": "The paper describes using a multi-modal approach that combines images, text, and GPS data for navigation.",
          "quote": "Our policy model fuses multi-modal observations in the form of variable resolution images, visible text, and simulated GPS data to navigate to a goal door."
        },
        "caracteristics": [
          {
            "value": "Neural Network",
            "justification": "The model integrates various types of data through a neural network architecture to perform the navigation tasks.",
            "quote": "Our policy model fuses multi-modal observations in the form of variable resolution images, visible text, and simulated GPS data to navigate to a goal door."
          }
        ],
        "is_contributed": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "is_executed": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "SEVN",
          "justification": "This is the primary dataset introduced and used throughout the paper.",
          "quote": "This work introduces SEVN, a sidewalk simulation environment."
        },
        "role": "contributed",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "OpenAI Gym",
          "justification": "The SEVN simulator is based on the OpenAI Gym environment.",
          "quote": "The SEVN Simulator is based on the OpenAI Gym environment."
        },
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "NetworkX",
          "justification": "NetworkX is used to implement the panorama graph for navigation.",
          "quote": "Our panorama graph is implemented in NetworkX."
        },
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 920,
    "prompt_tokens": 13040,
    "total_tokens": 13960
  }
}