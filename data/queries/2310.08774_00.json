{
  "paper": "2310.08774.txt",
  "words": 15732,
  "extractions": {
    "description": "This research paper introduces PhyloGFN, the first adaptation of Generative Flow Networks (GFlowNets) to perform Bayesian and parsimony-based phylogenetic inference and demonstrates its competitive performance against state-of-the-art methods.",
    "title": {
      "value": "PhyloGFN: Phylogenetic Inference with Generative Flow Networks",
      "justification": "The title of the paper clearly and succinctly reflects the content and main contribution of the research.",
      "quote": "PHYLO GFN: PHYLOGENETIC INFERENCE WITH GENERATIVE FLOW NETWORKS."
    },
    "type": {
      "value": "empirical study",
      "justification": "The paper presents empirical results demonstrating the performance of PhyloGFN against other methods on multiple datasets.",
      "quote": "We evaluate PhyloGFN on a suite of 8 real-world benchmark datasets (Table S1 in Appendix C) that is standard in the literature."
    },
    "research_field": {
      "value": "Deep Learning",
      "justification": "The paper applies deep learning models, specifically Generative Flow Networks, to the problem of phylogenetic inference.",
      "quote": "In this paper, we adopt the framework of generative flow networks (GFlowNets) to tackle two core problems in phylogenetics: parsimony-based and Bayesian phylogenetic inference."
    },
    "sub_research_field": {
      "value": "Generative Models",
      "justification": "The core contribution of the paper is the development and application of a generative model (PhyloGFN) for phylogenetic inference.",
      "quote": "We propose PhyloGFN, the first adaptation of GFlowNets to the task of Bayesian and parsimony-based phylogenetic inference."
    },
    "models": [
      {
        "name": {
          "value": "PhyloGFN",
          "justification": "PhyloGFN is explicitly designed, developed, and evaluated in the paper.",
          "quote": "We propose PhyloGFN, the first adaptation of GFlowNets to the task of Bayesian and parsimony-based phylogenetic inference."
        },
        "role": "contributed",
        "type": {
          "value": "Generative Flow Network (GFlowNet)",
          "justification": "The model extends and adapts the Generative Flow Networks framework for phylogenetic inference.",
          "quote": "Coming from the intersection of variational inference and reinforcement learning is the class of models known as generative flow networks (GFlowNets; Bengio et al., 2021)."
        },
        "mode": "trained"
      },
      {
        "name": {
          "value": "VBPI-GNN",
          "justification": "VBPI-GNN is used as a baseline comparison method in the paper.",
          "quote": "Among these methods, some model only a limited portion of the space of tree topologies, while others are weaker in marginal likelihood estimation due to simplifying assumptions. In parsimony analysis, state-of-the-art methods such as PAUP* (Swofford, 1998) have extensively relied on heuristic search algorithms that are efficient but lack theoretical foundations and guarantees."
        },
        "role": "referenced",
        "type": {
          "value": "Variational Bayesian Phylogenetic Inference",
          "justification": "The model employs graph neural networks to learn tree topological embeddings for variational inference.",
          "quote": "Among these methods, some model only a limited portion of the space of tree topologies, while others are weaker in marginal likelihood estimation due to simplifying assumptions. In parsimony analysis, state-of-the-art methods such as PAUP* (Swofford, 1998) have extensively relied on heuristic search algorithms that are efficient but lack theoretical foundations and guarantees."
        },
        "mode": "inference"
      },
      {
        "name": {
          "value": "GeoPhy",
          "justification": "GeoPhy is used as a baseline comparison method in the paper.",
          "quote": "GeoPhy (Mimori & Hamada, 2023) models the tree topology distribution in continuous space by mapping continuous-valued coordinates to tree topologies, using the same technique as VBPI-GNN to model tree topological embeddings."
        },
        "role": "referenced",
        "type": {
          "value": "Generative Model",
          "justification": "The model is a generative model that maps continuous-valued coordinates to tree topologies.",
          "quote": "GeoPhy (Mimori & Hamada, 2023) models the tree topology distribution in continuous space by mapping continuous-valued coordinates to tree topologies."
        },
        "mode": "inference"
      },
      {
        "name": {
          "value": "VaiPhy",
          "justification": "VaiPhy is used as a baseline comparison method in the paper.",
          "quote": "VaiPhy (Koptagel et al., 2022) approximates the posterior distribution in the augmented space of tree topologies, edge lengths, and ancestral sequences. Combined with combinatorial sequential Monte Carlo (CSMC; Moretti et al., 2021), the proposed method enables faster estimation of marginal likelihood."
        },
        "role": "referenced",
        "type": {
          "value": "Variational Inference",
          "justification": "VaiPhy employs variational inference to approximate the posterior distribution in the augmented space of tree topologies.",
          "quote": "VaiPhy (Koptagel et al., 2022) approximates the posterior distribution in the augmented space of tree topologies, edge lengths, and ancestral sequences."
        },
        "mode": "inference"
      },
      {
        "name": {
          "value": "MrBayes",
          "justification": "MrBayes is used as a state-of-the-art baseline comparison method in the paper.",
          "quote": "Markov chain Monte Carlo (MCMC)-based algorithms are commonly employed for Bayesian phylogenetics, with notable examples including MrBayes and RevBayes (Ronquist et al., 2012; Högna et al., 2016), which are considered state-of-the-art in the field."
        },
        "role": "referenced",
        "type": {
          "value": "Markov chain Monte Carlo (MCMC)",
          "justification": "MrBayes employs MCMC algorithms for Bayesian phylogenetic inference.",
          "quote": "Markov chain Monte Carlo (MCMC)-based algorithms are commonly employed for Bayesian phylogenetics, with notable examples including MrBayes and RevBayes."
        },
        "mode": "inference"
      },
      {
        "name": {
          "value": "RevBayes",
          "justification": "RevBayes is used as a state-of-the-art baseline comparison method in the paper.",
          "quote": "Markov chain Monte Carlo (MCMC)-based algorithms are commonly employed for Bayesian phylogenetics, with notable examples including MrBayes and RevBayes (Ronquist et al., 2012; Högna et al., 2016), which are considered state-of-the-art in the field."
        },
        "role": "referenced",
        "type": {
          "value": "Markov chain Monte Carlo (MCMC)",
          "justification": "RevBayes employs MCMC algorithms for Bayesian phylogenetic inference.",
          "quote": "Markov chain Monte Carlo (MCMC)-based algorithms are commonly employed for Bayesian phylogenetics, with notable examples including MrBayes and RevBayes (Ronquist et al., 2012; Högna et al., 2016), which are considered state-of-the-art in the field."
        },
        "mode": "inference"
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "DS1",
          "justification": "DS1 is one of the real-world benchmark datasets on which PhyloGFN was evaluated.",
          "quote": "We evaluate PhyloGFN on a suite of 8 real-world benchmark datasets (Table S1 in Appendix C) that is standard in the literature."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "DS2",
          "justification": "DS2 is one of the real-world benchmark datasets on which PhyloGFN was evaluated.",
          "quote": "We evaluate PhyloGFN on a suite of 8 real-world benchmark datasets (Table S1 in Appendix C) that is standard in the literature."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "DS3",
          "justification": "DS3 is one of the real-world benchmark datasets on which PhyloGFN was evaluated.",
          "quote": "We evaluate PhyloGFN on a suite of 8 real-world benchmark datasets (Table S1 in Appendix C) that is standard in the literature."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "DS4",
          "justification": "DS4 is one of the real-world benchmark datasets on which PhyloGFN was evaluated.",
          "quote": "We evaluate PhyloGFN on a suite of 8 real-world benchmark datasets (Table S1 in Appendix C) that is standard in the literature."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "DS5",
          "justification": "DS5 is one of the real-world benchmark datasets on which PhyloGFN was evaluated.",
          "quote": "We evaluate PhyloGFN on a suite of 8 real-world benchmark datasets (Table S1 in Appendix C) that is standard in the literature."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "DS6",
          "justification": "DS6 is one of the real-world benchmark datasets on which PhyloGFN was evaluated.",
          "quote": "We evaluate PhyloGFN on a suite of 8 real-world benchmark datasets (Table S1 in Appendix C) that is standard in the literature."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "DS7",
          "justification": "DS7 is one of the real-world benchmark datasets on which PhyloGFN was evaluated.",
          "quote": "We evaluate PhyloGFN on a suite of 8 real-world benchmark datasets (Table S1 in Appendix C) that is standard in the literature."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "DS8",
          "justification": "DS8 is one of the real-world benchmark datasets on which PhyloGFN was evaluated.",
          "quote": "We evaluate PhyloGFN on a suite of 8 real-world benchmark datasets (Table S1 in Appendix C) that is standard in the literature."
        },
        "role": "used"
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is one of the libraries used for implementing the models in the research.",
          "quote": "The dynamic programming, or recursion, is essentially a post-order traversal of the tree and 𝑃(𝐿 𝑢𝑖 | 𝑎 𝑖𝑢 ) is calculated at every internal node 𝑢, and we use one-hot encoding of the sequences to represent the conditional probabilities at the leaves."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "TensorFlow",
          "justification": "TensorFlow is one of the libraries used for implementing the models in the research.",
          "quote": "The dynamic programming, or recursion, is essentially a post-order traversal of the tree and 𝑃(𝐿 𝑢𝑖 | 𝑎 𝑖𝑢 ) is calculated at every internal node 𝑢, and we use one-hot encoding of the sequences to represent the conditional probabilities at the leaves."
        },
        "role": "used"
      }
    ]
  },
  "usage": {
    "completion_tokens": 2650,
    "prompt_tokens": 33538,
    "total_tokens": 36188
  }
}