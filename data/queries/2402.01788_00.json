{
  "paper": "2402.01788.txt",
  "words": 6049,
  "extractions": {
    "description": "The paper introduces LitLLM, a toolkit designed to assist researchers in conducting literature reviews using Retrieval Augmented Generation (RAG) principles. The system leverages Large Language Models (LLMs) for summarizing abstracts, retrieving and re-ranking relevant papers, and generating related work sections, aiming to reduce the time and effort required for literature reviews.",
    "title": {
      "value": "LitLLM: A Toolkit for Scientific Literature Review",
      "justification": "The title is explicitly mentioned at the beginning of the paper.",
      "quote": "LitLLM: A Toolkit for Scientific Literature Review"
    },
    "type": {
      "value": "empirical",
      "justification": "The paper presents a system, LitLLM, and provides implementation details, as well as user experiences and usage studies, indicating its empirical nature.",
      "quote": "As a preliminary study, we provided access to our user interface to 5 different researchers who worked through the demo to write literature reviews and validate the systemâ€™s efficacy."
    },
    "research_field": {
      "value": "Natural Language Processing",
      "justification": "The paper focuses on the use of LLMs and RAG techniques, which are core topics in the field of Natural Language Processing.",
      "quote": "Following recent advances in large language models (LLMs), a new set of systems provides even more advanced features."
    },
    "sub_research_field": {
      "value": "Scientific Literature Review",
      "justification": "The paper specifically addresses the task of conducting literature reviews using NLP techniques.",
      "quote": "LitLLM is an interactive tool to help scientists write the literature review or related work section of a scientific paper starting from a user-provided abstract."
    },
    "models": [
      {
        "name": {
          "value": "GPT-3.5-turbo",
          "justification": "The paper mentions the use of GPT-3.5-turbo for generating results.",
          "quote": "In this work, we use OpenAI API to generate results for LLM using GPT-3.5-turbo and GPT-4 model."
        },
        "role": "used",
        "type": {
          "value": "Large Language Model (LLM)",
          "justification": "GPT-3.5-turbo is a variant of OpenAI's GPT-3 specialized for turbo inference.",
          "quote": "In this work, we use OpenAI API to generate results for LLM using GPT-3.5-turbo and GPT-4 model."
        },
        "mode": "inference"
      },
      {
        "name": {
          "value": "GPT-4",
          "justification": "The paper mentions the use of GPT-4 for generating results.",
          "quote": "In this work, we use OpenAI API to generate results for LLM using GPT-3.5-turbo and GPT-4 model."
        },
        "role": "used",
        "type": {
          "value": "Large Language Model (LLM)",
          "justification": "GPT-4 is one of OpenAI's most advanced language models.",
          "quote": "In this work, we use OpenAI API to generate results for LLM using GPT-3.5-turbo and GPT-4 model."
        },
        "mode": "inference"
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "S2ORC (Semantic Scholar Open Research Corpus)",
          "justification": "The paper mentions using the Semantic Scholar API and its academic corpus for retrieving relevant papers, which includes datasets like S2ORC.",
          "quote": "We query the Semantic Scholar API available through the Semantic Scholar Open Data Platform to search for the relevant papers."
        },
        "role": "used"
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "OpenAI API",
          "justification": "The paper mentions using the OpenAI API for generating results using GPT-3.5-turbo and GPT-4 models.",
          "quote": "In this work, we use OpenAI API to generate results for LLM using GPT-3.5-turbo and GPT-4 model."
        },
        "role": "used"
      },
      {
        "name": {
          "value": "Gradio",
          "justification": "The paper mentions using Gradio for building the system's user interface.",
          "quote": "We build our system using Gradio, which provides a nice interface to quickly and efficiently build system demos."
        },
        "role": "used"
      }
    ]
  },
  "usage": {
    "completion_tokens": 793,
    "prompt_tokens": 10094,
    "total_tokens": 10887
  }
}