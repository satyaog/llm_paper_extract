{
  "paper": "2310.18807.txt",
  "words": 9765,
  "extractions": {
    "title": {
      "value": "OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning",
      "justification": "Title as mentioned in the provided content.",
      "quote": "OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning"
    },
    "description": "The paper presents OC-NMN, a modular neural network model designed for visual generative analogical reasoning. It introduces the Arith-MNIST dataset to evaluate the model's ability to generalize out-of-distribution by performing arithmetic operations on MNIST digits. Key innovations include leveraging object-centric inductive biases and a compositional data augmentation framework inspired by human imagination.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper involves experimental evaluation, dataset creation, and comparison of model performance.",
      "quote": "In this section, we present the experimental results of applying OC-NMN to different splits of the Arith-MNIST dataset, and compare it against several baseline approaches."
    },
    "primary_research_field": {
      "value": "Deep Learning",
      "justification": "The paper deals with neural networks, model generalization, and compositional data augmentation in the context of deep learning.",
      "quote": "Such capacity is not yet attained for machine learning systems. In this work, in the context of visual reasoning, we show how modularity can be leveraged to derive a compositional data augmentation framework inspired by imagination."
    },
    "sub_research_fields": [
      {
        "value": "Visual Reasoning",
        "justification": "The focus of the paper is on models and datasets for visual generative analogical reasoning, which falls under the subfield of visual reasoning.",
        "quote": "Our method, denoted Object-centric Compositional Neural Module Network (OC-NMN), decomposes visual generative reasoning tasks into a series of primitives applied to objects without using a domain-specific language."
      }
    ],
    "models": [
      {
        "name": {
          "value": "Neural Abstract Reasoner (NAR)",
          "justification": "NAR is one of the models used for comparison in the experiments.",
          "quote": "we evaluate GPT-4 on the easy split and obtain an accuracy of 16 in the best case.\n\nIn this work, we take a step towards addressing the ARC challenge by designing a new and simpler generative benchmark, which we call Arith-MNIST."
        },
        "caracteristics": [
          {
            "value": "Neural Network",
            "justification": "NAR is based on neural network architectures, specifically designed for abstract reasoning tasks.",
            "quote": "To the best of our knowledge, the only existing neural network model that can readily tackle generative visual reasoning tasks is the Neural Abstract Reasoner (NAR) (Kolev et al., 2020)."
          }
        ],
        "is_contributed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "DNC-GRU",
          "justification": "This model serves as one of the baselines for comparison in the experiments.",
          "quote": "The second baseline consists of a stack of Transformer encoder layers, and takes as input a set composed of the query slots, the controller output,and a CLS token from which we retrieve the final answer. We denote this model DNC-Transformer."
        },
        "caracteristics": [
          {
            "value": "Neural Network",
            "justification": "DNC-GRU is a neural network model utilizing GRU cells for its architecture.",
            "quote": "The non-modular DNC-GRU baseline is on par with the others on the easy set, but when the tasks get more complicated (i.e. more concepts required to be learnt and assembled to solve the tasks) it performs subsequently worse than other executors."
          }
        ],
        "is_contributed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "DNC-Transformer",
          "justification": "This model is another baseline used for comparison.",
          "quote": "We denote this model DNC-Transformer. All architectural details and hyperparameters are described in the Appendix."
        },
        "caracteristics": [
          {
            "value": "Neural Network",
            "justification": "The DNC-Transformer model uses transformer architecture in its design.",
            "quote": "The second baseline consists of a stack of Transformer encoder layers, and takes as input a set composed of the query slots, the controller output, and a CLS token from which we retrieve the final answer. We denote this model DNC-Transformer."
          }
        ],
        "is_contributed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "FLAN-T5",
          "justification": "FLAN-T5 is evaluated on the text equivalent tasks in the experiments.",
          "quote": "We also report the performance of a state-of-the-art language model baseline FLAN-T5 on the text equivalent tasks."
        },
        "caracteristics": [
          {
            "value": "Language Model",
            "justification": "FLAN-T5 is a language model.",
            "quote": "Text Version. We consider two state-of-the-art language models: FLAN-T5 (Chung et al., 2022) fine-tuned on our task and GPT-4."
          }
        ],
        "is_contributed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "GPT-4",
          "justification": "GPT-4 is used to evaluate generalization to unseen digit-color configurations.",
          "quote": "We evaluate GPT-4 on the easy split and obtain an accuracy of 16 in the best case. More details about the GPT-4 training can be found in the Appendix."
        },
        "caracteristics": [
          {
            "value": "Language Model",
            "justification": "GPT-4 is a large-scale language model.",
            "quote": "In an attempt to improve GPT-4 performance, we experimented with different prompts....The best test result we obtained was 16% on the same test samples."
          }
        ],
        "is_contributed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Abstract Reasoning Corpus (ARC)",
          "justification": "The ARC dataset is specifically mentioned as a reference point for generative reasoning tasks.",
          "quote": "To that end, Chollet (2019) proposed a generative reasoning task, the Abstract Reasoning Corpus (ARC), where the model is given a few examples of input-output (I/O) pairs and has to understand the underlying common program that was applied to the inputs to obtain the outputs."
        },
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Differentiable Neural Computation (DNC)",
          "justification": "DNC is specifically mentioned as the controller architecture for several models used in the paper.",
          "quote": "The controller moduleâ€™s architecture is the same for all the baselines considered (including our model) and corresponds to the Differentiable Neural Computer controller (Graves et al., 2016) proposed in Neural Abstract Reasoner (Kolev et al., 2020)."
        },
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1298,
    "prompt_tokens": 16113,
    "total_tokens": 17411
  }
}