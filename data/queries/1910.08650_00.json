{
  "paper": "1910.08650.txt",
  "words": 7405,
  "extractions": {
    "description": "The paper explores methods for differentiating between out-of-distribution (OOD) sets to select the most effective one for training calibrated convolutional neural networks (CNNs) for OOD detection. The authors propose computationally efficient metrics based on generalization errors of augmented-CNNs (A-CNNs) and verify their effectiveness empirically.",
    "title": {
      "value": "Toward Metrics for Differentiating Out-of-Distribution Sets",
      "justification": "This is the official title of the paper as given in the provided text.",
      "quote": "Toward Metrics for Differentiating Out-of-Distribution Sets"
    },
    "type": {
      "value": "Empirical Study",
      "justification": "The paper is empirical as it proposes methods and evaluates them through a series of experiments on image and audio classification tasks.",
      "quote": "We conduct a series of experiments on several classification tasks including two image benchmarks, namely CIFAR-10 and SVHN, and one audio benchmark, namely Urban-Sound [28]."
    },
    "research_field": {
      "value": "Machine Learning",
      "justification": "The research focuses on improving convolutional neural networks for out-of-distribution detection, a prominent topic in machine learning.",
      "quote": "Vanilla CNNs, as uncalibrated classifiers, suffer from classifying out-of-distribution (OOD) samples nearly as confidently as in-distribution samples."
    },
    "sub_research_field": {
      "value": "Deep Learning",
      "justification": "The paper involves deep learning models, specifically Convolutional Neural Networks (CNNs), for OOD detection and introduces augmented and calibrated CNNs.",
      "quote": "To tackle this challenge, some recent works have demonstrated the gains of leveraging available OOD sets for training end-to-end calibrated CNNs."
    },
    "models": [
      {
        "name": {
          "value": "A-CNN",
          "justification": "Augmented Convolutional Neural Network, a vanilla CNN with an additional rejection class used for OOD detection.",
          "quote": "We exploit A-CNN as an end-to-end model for OOD detection task."
        },
        "role": "Contributed",
        "type": {
          "value": "Convolutional Neural Network",
          "justification": "A-CNN is based on the architecture of Convolutional Neural Networks.",
          "quote": "an OOD set is recognized as a proper (effective) if it leads to training of A-CNN with low generalization errors for both in-distribution and unseen OOD sets."
        },
        "mode": "Trained"
      },
      {
        "name": {
          "value": "Vanilla CNN",
          "justification": "Standard Convolutional Neural Network used for benchmarking and training as part of the study.",
          "quote": "Vanilla CNNs, as uncalibrated classifiers, suffer from classifying out-of-distribution (OOD) samples nearly as confidently as in-distribution samples."
        },
        "role": "Used",
        "type": {
          "value": "Convolutional Neural Network",
          "justification": "Vanilla CNN refers to the standard form of Convolutional Neural Network.",
          "quote": "Vanilla CNNs, as uncalibrated classifiers, suffer from classifying out-of-distribution (OOD) samples nearly as confidently as in-distribution samples."
        },
        "mode": "Trained"
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "One of the benchmark datasets used in the paper for testing and training.",
          "quote": "In an extensive series of experiments on image and audio classification tasks, we empirically show that A-CNNs and calibrated vanilla CNNs trained on the most protective OOD set have higher detection rates (lower generalization error) on unseen OOD sets in comparison with those trained on the least protective OOD set."
        },
        "role": "Used"
      },
      {
        "name": {
          "value": "SVHN",
          "justification": "Another benchmark dataset used in the paper for empirical evaluations.",
          "quote": "We conduct a series of experiments on several classification tasks including two image benchmarks, namely CIFAR-10 and SVHN, and one audio benchmark, namely Urban-Sound [28]."
        },
        "role": "Used"
      },
      {
        "name": {
          "value": "Urban-Sound",
          "justification": "This is the audio benchmark dataset used for the experiments performed in the paper.",
          "quote": "We conduct a series of experiments on several classification tasks including two image benchmarks, namely CIFAR-10 and SVHN, and one audio benchmark, namely Urban-Sound [28]."
        },
        "role": "Used"
      },
      {
        "name": {
          "value": "TinyImageNet",
          "justification": "Another dataset used as an out-of-distribution set in the experiments.",
          "quote": "for image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets"
        },
        "role": "Used"
      },
      {
        "name": {
          "value": "ISUN",
          "justification": "Used as one of the out-of-distribution sets for image classification tasks.",
          "quote": "for image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets"
        },
        "role": "Used"
      },
      {
        "name": {
          "value": "LSUN",
          "justification": "Also used as an out-of-distribution set in the experiments for image classification tasks.",
          "quote": "for image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets"
        },
        "role": "Used"
      },
      {
        "name": {
          "value": "Gaussian Noise Dataset",
          "justification": "Synthetic dataset used in the experiments to evaluate the models.",
          "quote": "and Gaussian noise as a synthetic OOD set."
        },
        "role": "Used"
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "Used as an out-of-distribution dataset in the experiments.",
          "quote": "for image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets"
        },
        "role": "Used"
      },
      {
        "name": {
          "value": "ECS (Environmental Sound Classification)",
          "justification": "Used in the audio classification tasks as an out-of-distribution set.",
          "quote": "OOD sets considered are TuT [25], Google Command [32] and ECS (Environmental Sound Classification) [26], as well as white-noise sound as a synthetic OOD set."
        },
        "role": "Used"
      },
      {
        "name": {
          "value": "Google Command",
          "justification": "Used in the audio classification experiments as an OOD set.",
          "quote": "OOD sets considered are TuT [25], Google Command [32] and ECS (Environmental Sound Classification) [26], as well as white-noise sound as a synthetic OOD set."
        },
        "role": "Used"
      },
      {
        "name": {
          "value": "TuT",
          "justification": "This dataset was used for audio classification tasks as an out-of-distribution set.",
          "quote": "OOD sets considered are TuT [25], Google Command [32] and ECS (Environmental Sound Classification) [26], as well as white-noise sound as a synthetic OOD set."
        },
        "role": "Used"
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1689,
    "prompt_tokens": 12856,
    "total_tokens": 14545
  }
}