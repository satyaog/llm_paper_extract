{
  "paper": "1911.05873.txt",
  "words": 18973,
  "extractions": {
    "title": {
      "value": "A Reduction from Reinforcement Learning to No-Regret Online Learning",
      "justification": "It is the title provided by the source document.",
      "quote": "A Reduction from Reinforcement Learning to No-Regret Online Learning"
    },
    "description": "The paper presents a reduction methodology from reinforcement learning (RL) to no-regret online learning using the saddle-point formulation of RL. This approach decomposes the RL problem into two parts: regret minimization and function approximation. By applying this reduction, new RL algorithms can be systematically designed. The paper also proposes an RL algorithm based on mirror descent via a generative-model oracle, providing provable performance guarantees.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper proposes a new algorithm for RL and demonstrates its performance through empirical evaluation.",
      "quote": "We demonstrate this idea by devising a simple RL algorithm based on mirror descent and the generative-model oracle."
    },
    "primary_research_field": {
      "value": "Deep Learning",
      "justification": "The paper's focus is on devising algorithms for reinforcement learning, which is a subfield of deep learning.",
      "quote": "Reinforcement Learning (RL) is a fundamental problem for sequential decision making in unknown environments."
    },
    "sub_research_fields": [
      {
        "value": "Reinforcement Learning",
        "justification": "The main theme of the paper is to reduce reinforcement learning problems to no-regret online learning and to design new RL algorithms.",
        "quote": "We present a reduction from reinforcement learning (RL) to no-regret online learning based on the saddle-point formulation of RL."
      }
    ],
    "models": [
      {
        "name": {
          "value": "mirror descent algorithm",
          "justification": "The paper proposes and evaluates a simple RL algorithm based on mirror descent.",
          "quote": "As a demonstration, we design an RL algorithm based on arguably the simplest online learning algorithm: mirror descent."
        },
        "caracteristics": [
          {
            "value": "Reinforcement Learning Algorithm",
            "justification": "The mirror descent algorithm is used as the basis for the proposed RL algorithm in the paper.",
            "quote": "we design an RL algorithm based on arguably the simplest online learning algorithm: mirror descent."
          }
        ],
        "is_contributed": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "is_executed": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "tabular Markov decision process (MDP)",
          "justification": "The paper demonstrates the effectiveness of its proposed algorithm using tabular MDPs.",
          "quote": "We prove that, for any tabular Markov decision process (MDP), with probability at least 1 − δ, this algorithm learns an ǫ-optimal policy"
        },
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "generative-model oracle",
          "justification": "The generative-model oracle is used in the paper for implementing the proposed RL algorithm.",
          "quote": "Assuming a generative model, we prove that, for any tabular Markov decision process"
        },
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 559,
    "prompt_tokens": 32349,
    "total_tokens": 32908
  }
}